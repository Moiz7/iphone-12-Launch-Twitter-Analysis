{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter Data Analysis",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfMD4kb2QO6U"
      },
      "source": [
        "import sys\n",
        "import tweepy,json\n",
        "from tweepy import OAuthHandler\n",
        "from tweepy import API\n",
        "from tweepy import Stream\n",
        "from tweepy.streaming import StreamListener\n",
        "\n",
        "# Replace the \"None\"s by your own credentials\n",
        "ACCESS_TOKEN = \"1173156479786000386-glFQXlJsdRlmmyXuJEVIap326UPTVt\"\n",
        "ACCESS_TOKEN_SECRET = \"5ePMGYr8gQmOsofEQ8gx1VZpqLP7Oyl8E7qFmzwbqkwEN\"\n",
        "CONSUMER_KEY = \"AJuWhND0dGUdVvTgUCGs087Zo\"\n",
        "CONSUMER_SECRET = \"D0h9CIdXmhFPdxUxtHeiQpGu2KpUMUowUtunEEN5OGkk2VjDhe\"\n",
        "\n",
        "auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
        "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
        "api = API(auth, wait_on_rate_limit=True,\n",
        "          wait_on_rate_limit_notify=True)\n",
        "\n",
        "class Listener(tweepy.StreamListener):\n",
        "    def __init__(self, api=None):\n",
        "        super(Listener, self).__init__()\n",
        "        self.num_tweets = 0\n",
        "        self.file = open(\"tweetsstream.txt\", \"w\")\n",
        "\n",
        "    def on_status(self, status):\n",
        "        tweet = status._json\n",
        "        self.file.write( json.dumps(tweet) + '\\n' )\n",
        "        self.num_tweets += 1\n",
        "        if self.num_tweets < 1000:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "        self.file.close()\n",
        "\n",
        "    def on_error(self, status):\n",
        "        print(status)\n",
        "\n",
        "l = Listener()\n",
        "stream = tweepy.Stream(auth, l)\n",
        "# This line filters Twitter Streams to capture data by keywords:\n",
        "stream.filter(track=['apple', 'iphone 12'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9phl2CzZ6oWn",
        "outputId": "491fd772-a8c2-4d8a-e7f1-88ebde1dff07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "# Import package\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# String of path to file: tweets_data_path\n",
        "tweets_data_path='tweetsstream.txt'\n",
        "\n",
        "# Initialize empty list to store tweets: tweets_data\n",
        "tweets_data=[]\n",
        "\n",
        "# Open connection to file\n",
        "tweets_file = open(tweets_data_path, \"r\")\n",
        "\n",
        "# Read in tweets and store in list: tweets_data\n",
        "for line in tweets_file:\n",
        "    tweet=json.loads(line)\n",
        "    tweets_data.append(tweet)\n",
        "    \n",
        "\n",
        "# Close connection to file\n",
        "tweets_file.close()\n",
        "\n",
        "# Print the keys of the first tweet dict\n",
        "print(tweets_data[0].keys())\n",
        "\n",
        "tweets_df=pd.DataFrame(tweets_data,columns=['created_at','text','lang'])\n",
        "tweets_df['created_at']=pd.to_datetime(tweets_df['created_at'])\n",
        "\n",
        "print(tweets_df.head())\n",
        "#print(tweets_df.shape)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['created_at', 'id', 'id_str', 'text', 'source', 'truncated', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'quoted_status_id', 'quoted_status_id_str', 'quoted_status', 'quoted_status_permalink', 'is_quote_status', 'quote_count', 'reply_count', 'retweet_count', 'favorite_count', 'entities', 'favorited', 'retweeted', 'filter_level', 'lang', 'timestamp_ms'])\n",
            "                 created_at  ... lang\n",
            "0 2020-10-14 09:27:31+00:00  ...   tl\n",
            "1 2020-10-14 09:27:31+00:00  ...   in\n",
            "2 2020-10-14 09:27:31+00:00  ...   en\n",
            "3 2020-10-14 09:27:31+00:00  ...   ja\n",
            "4 2020-10-14 09:27:31+00:00  ...   th\n",
            "\n",
            "[5 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gImX4aokGxK-",
        "outputId": "82f2863a-0317-46d5-a1d0-241953180a7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "pip install vaderSentiment"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vaderSentiment\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/fc/310e16254683c1ed35eeb97386986d6c00bc29df17ce280aed64d55537e9/vaderSentiment-3.3.2-py2.py3-none-any.whl (125kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 23.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2020.6.20)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNuNEZsOJA_b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB2dkk97D7IZ",
        "outputId": "852e96e1-4fde-4d56-e538-f61fbbdd76f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QebMQg-gIev1",
        "outputId": "8d8f2af3-3988-4659-8958-eb7cbdeb2de1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "sentiment_scores = tweets_df['text'].apply(sid.polarity_scores)\n",
        "print(sentiment_scores)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0      {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
            "1      {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
            "2      {'neg': 0.249, 'neu': 0.751, 'pos': 0.0, 'comp...\n",
            "3      {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
            "4      {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
            "                             ...                        \n",
            "994    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
            "995    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
            "996    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
            "997    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
            "998    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
            "Name: text, Length: 999, dtype: object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vvpb__v2K8N7",
        "outputId": "28c1a949-a649-455c-99c7-c9daee0434a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "#sentiment = sentiment_scores.apply(lambda x: x['compound'])\n",
        "tweets_df['sentiment_score']=sentiment_scores.apply(lambda x: x['compound'])\n",
        "#sentiment_i=sentiment.resample('1 min').mean()\n",
        "print(tweets_df)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   created_at  ... sentiment_score\n",
            "0   2020-10-14 09:27:31+00:00  ...          0.0000\n",
            "1   2020-10-14 09:27:31+00:00  ...          0.0000\n",
            "2   2020-10-14 09:27:31+00:00  ...         -0.8074\n",
            "3   2020-10-14 09:27:31+00:00  ...          0.0000\n",
            "4   2020-10-14 09:27:31+00:00  ...          0.0000\n",
            "..                        ...  ...             ...\n",
            "994 2020-10-14 09:28:30+00:00  ...          0.0000\n",
            "995 2020-10-14 09:28:30+00:00  ...          0.0000\n",
            "996 2020-10-14 09:28:30+00:00  ...          0.0000\n",
            "997 2020-10-14 09:28:30+00:00  ...          0.0000\n",
            "998 2020-10-14 09:28:30+00:00  ...          0.0000\n",
            "\n",
            "[999 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}